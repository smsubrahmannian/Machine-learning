{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/fastai/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.core.dtypes.common import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, ParameterGrid\n",
    "from scipy.stats import randint as sp_randint\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Steps for logistic regression \n",
    " 1.Look at distribution of response variable to determine if it's a balanced, imbalanced or multi-class problem.<br>\n",
    " 2.Finalise metric <br>\n",
    " 3.Find the numerical features and scale them <br>\n",
    " 4.Determine which columns are categorical(all columns except target variable) and one hot encode them <br>\n",
    " 5.Select a splitting method(random, last) and split it into train and validation sets. <br>\n",
    " 6.Check if cross fold validation is a good idea <br>\n",
    " 7.Hyper-parameter optimisation <br>\n",
    " 8.Train final model on complete data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            display(df)\n",
    "\n",
    "def train_cats(df):\n",
    "    for col_name, col in df.items():\n",
    "        if is_string_dtype(col): df[col_name] = col.astype('category').cat.as_ordered()\n",
    "\n",
    "def fix_missing(df, col, name):\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum():\n",
    "            df[name] = col.fillna(col.median())\n",
    "            \n",
    "# Convert string columns in test df into categorical columns, using cat codes from training data\n",
    "def apply_cats(df, trn):\n",
    "    for n,c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n",
    "            \n",
    "def scale_vars(df, mapper):\n",
    "#     warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    return mapper\n",
    "\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n",
    "        df[name] = col.cat.codes+1\n",
    "        \n",
    "def proc_df(df, y_fld, do_scale=False, max_n_cat=None, mapper=None,nonlinear=True):\n",
    "    df = df.copy()\n",
    "    y = df[y_fld].values\n",
    "    df.drop([y_fld], axis=1, inplace=True)\n",
    "    for n,c in df.items(): fix_missing(df, c, n)\n",
    "    if do_scale: mapper = scale_vars(df, mapper)\n",
    "    if nonlinear:\n",
    "        for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    res = [pd.get_dummies(df, dummy_na=True), y]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res\n",
    "def score_for_fi(x1, x2):\n",
    "    # this controls the metric used for feature importance calculation\n",
    "    return metrics.mean_squared_error(x1, x2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dta = sm.datasets.fair.load_pandas().data\n",
    "# add \"affair\" column: 1 represents having affairs, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)\n",
    "dta.drop('affairs',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
       "\n",
       "   occupation_husb  affair  \n",
       "0              5.0       1  \n",
       "1              4.0       1  \n",
       "2              5.0       1  \n",
       "3              5.0       1  \n",
       "4              4.0       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dataset\n",
    "The dataset is the affairs dataset that comes with Statsmodels. It was derived from a survey of women in 1974 by Redbook magazine, in which married women were asked about their participation in extramarital affairs. More information about the study is available in a 1978 paper from the Journal of Political Economy.\n",
    "\n",
    "Description of Variables\n",
    "The dataset contains 6366 observations of 9 variables:\n",
    "\n",
    "rate_marriage: woman's rating of her marriage (1 = very poor, 5 = very good)\n",
    "age: woman's age\n",
    "yrs_married: number of years married\n",
    "children: number of children\n",
    "religious: woman's rating of how religious she is (1 = not religious, 4 = strongly religious)\n",
    "educ: level of education (9 = grade school, 12 = high school, 14 = some college, 16 = college graduate, 17 = some graduate school, 20 = advanced degree)\n",
    "occupation: woman's occupation (1 = student, 2 = farming/semi-skilled/unskilled, 3 = \"white collar\", 4 = teacher/nurse/writer/technician/skilled, 5 = managerial/business, 6 = professional with advanced degree)\n",
    "occupation_husb: husband's occupation (same coding as above)\n",
    "affairs: time spent in extra-marital affairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of unique elements in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate_marriage      5\n",
       "age                6\n",
       "yrs_married        7\n",
       "children           6\n",
       "religious          4\n",
       "educ               6\n",
       "occupation         6\n",
       "occupation_husb    6\n",
       "affair             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.T.apply(lambda x: x.nunique(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dta.iloc[:,0:7]=dta.iloc[:,0:7].apply(lambda x:x.astype('category'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "    col = dta.columns[i]\n",
    "    dta[col]=dta[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate_marriage      category\n",
       "age                category\n",
       "yrs_married        category\n",
       "children           category\n",
       "religious          category\n",
       "educ               category\n",
       "occupation         category\n",
       "occupation_husb    category\n",
       "affair                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X,y= proc_df(dta,'affair',nonlinear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "Instructions:\n",
    "penalty='l2' \n",
    "Use dual: only when no of features> no of samples\n",
    "C=1.0 Inverse of lambda ( regularisation factor)\n",
    "multi_class='ovr' This is the standard technique ( one over rest, other options include multinomial: could be used with many solvers apart from the default solver 'liblinear' for faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6897779639715124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LogisticRegression(C=0.5,class_weight='balanced',\n",
    "                        multi_class='multinomial',solver='lbfgs',warm_start=True,n_jobs=-1, max_iter= 200)\n",
    "lm.fit(X, y)\n",
    "lm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991206030150754"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[779 321]\n",
      " [158 334]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.71      0.76      1100\n",
      "          1       0.51      0.68      0.58       492\n",
      "\n",
      "avg / total       0.73      0.70      0.71      1592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_valid, lm.predict(X_valid)))\n",
    "print(metrics.classification_report(y_valid, lm.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "No good summary available in sklearn, we might need to switch to statsmodel for the same. But I dont think we need to\n",
    "more than what is written above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Adhoc Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data2 = sm.datasets.ccard.load_pandas().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVGEXP</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>INCOMESQ</th>\n",
       "      <th>OWNRENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124.98</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>20.4304</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.85</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>5.8564</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.87</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.4516</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.79</td>\n",
       "      <td>95.8441</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVGEXP   AGE  INCOME  INCOMESQ  OWNRENT\n",
       "0  124.98  38.0    4.52   20.4304      1.0\n",
       "1    9.85  33.0    2.42    5.8564      0.0\n",
       "2   15.00  34.0    4.50   20.2500      1.0\n",
       "3  137.87  31.0    2.54    6.4516      0.0\n",
       "4  546.50  32.0    9.79   95.8441      1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AVGEXP      float64\n",
       "AGE         float64\n",
       "INCOME      float64\n",
       "INCOMESQ    float64\n",
       "OWNRENT     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in ['AGE','INCOMESQ']:\n",
    "    data2[col] = data2[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This dataset has both categorical and numerical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AVGEXP       float64\n",
       "AGE         category\n",
       "INCOME       float64\n",
       "INCOMESQ    category\n",
       "OWNRENT      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X,y,_= proc_df(data2,'OWNRENT',nonlinear=False,do_scale=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LogisticRegression(C=0.6,class_weight='balanced',multi_class='multinomial',\n",
    "                        solver='lbfgs',warm_start='True', max_iter=200)\n",
    "lm.fit(X_train, y_train)\n",
    "lm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters are: {'max_iter': 200, 'C': 4.091407244026523}\n",
      "Best score is 0.6908253037285296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as st\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, ParameterGrid\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "Clist = list(st.expon(0).rvs(size=20))\n",
    "grid = {\n",
    "    'C': Clist,\n",
    "    'max_iter':[200],\n",
    "}\n",
    "logit_search = LogisticRegression(C=0.5,class_weight='balanced',n_jobs=-1, max_iter= 200)\n",
    "m_cv = RandomizedSearchCV(estimator=logit_search, param_distributions=grid,verbose=1)\n",
    "m_cv.fit(X_train, y_train)\n",
    "print(\"Best parameters are: {}\".format(m_cv.best_params_))\n",
    "print(\"Best score is {}\".format(m_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logit_final = m_cv.best_estimator_\n",
    "logit_final.fit(X_train, y_train)\n",
    "logit_r2 = logit_final.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "0.7273869346733668\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator,random_forest\n",
    "from hyperopt import tpe\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25,random_state=0)\n",
    "X_train = X_train.values\n",
    "X_valid = X_valid.values\n",
    "\n",
    "estim = HyperoptEstimator(regressor=random_forest('affairs'),\n",
    "                          preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "estim.fit( X_train, y_train )\n",
    "print(estim.score( X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_rf =estim.best_model()['learner']\n",
    "final_rf.fit(X_train, y_train)\n",
    "rf_r2 = final_rf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 8.Extra tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7248743718592965\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator,extra_trees\n",
    "from hyperopt import tpe\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25,random_state=0)\n",
    "X_train = X_train.values\n",
    "X_valid = X_valid.values\n",
    "\n",
    "estim = HyperoptEstimator(regressor=extra_trees('affairs'),\n",
    "                          preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "estim.fit( X_train, y_train )\n",
    "print(estim.score( X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_et =estim.best_model()['learner']\n",
    "final_et.fit(X_train, y_train)\n",
    "et_r2 = final_et.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of models post tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extra Tree Classifier</td>\n",
       "      <td>0.724874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.690955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Models        R2\n",
       "0          Random Forest  0.727387\n",
       "1  Extra Tree Classifier  0.724874\n",
       "2    Logistic Regression  0.690955"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = [rf_r2,et_r2,logit_r2]\n",
    "models = ['Random Forest','Extra Tree Classifier','Logistic Regression']\n",
    "pd.DataFrame({'Models':models,'R2':r2_score}).sort_values(by='R2',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "2nd sem/ML/finals/Logistic Regression.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
